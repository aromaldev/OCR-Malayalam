{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Segmentation Pipeline",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "15OoeBpS_mBAQ8asf5TtsHp74sx0DIdTR",
      "authorship_tag": "ABX9TyPGW6CXujyXQo+1eQrXprte",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aromaldev/OCR-Malayalam/blob/master/Segmentation/Segmentation_Pipeline.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TROthf5jQpDM"
      },
      "source": [
        "# import shutil\n",
        "# shutil.rmtree('lines')\n",
        "# shutil.rmtree('words')\n",
        "# shutil.rmtree('chars')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uCAV2YS4a4z"
      },
      "source": [
        "#RLSA \n",
        "import numpy as np\n",
        "\n",
        "def iteration(image: np.ndarray, value: int) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    This method iterates over the provided image by converting 255's to 0's if the number of consecutive 255's are\n",
        "    less the \"value\" provided\n",
        "    \"\"\"\n",
        "\n",
        "    rows, cols = image.shape\n",
        "    for row in range(0,rows):\n",
        "        try:\n",
        "            start = image[row].tolist().index(0) # to start the conversion from the 0 pixel\n",
        "        except ValueError:\n",
        "            start = 0 # if '0' is not present in that row\n",
        "\n",
        "        count = start\n",
        "        for col in range(start, cols):\n",
        "            if image[row, col] == 0:\n",
        "                if (col-count) <= value and (col-count) > 0:\n",
        "                    image[row, count:col] = 0               \n",
        "                count = col  \n",
        "    return image \n",
        "\n",
        "def hvrlsa(image: np.ndarray, horizontal: bool = True,  vertical: bool = True, hvalue: int =0, vvalue: int = 0) -> np.ndarray:\n",
        "    \"\"\"\n",
        "    rlsa(RUN LENGTH SMOOTHING ALGORITHM) is to extract the block-of-text or the Region-of-interest(ROI) from the\n",
        "    document binary Image provided. Must pass binary image of ndarray type.\n",
        "    \"\"\"\n",
        "    \n",
        "    if isinstance(image, np.ndarray): # image must be binary of ndarray type\n",
        "        hvalue = int(hvalue) if hvalue>=0 else 0 # consecutive pixel position checker value to convert 255 to 0\n",
        "        vvalue = int(vvalue) if vvalue>=0 else 0\n",
        "        try:\n",
        "            # RUN LENGTH SMOOTHING ALGORITHM working horizontally on the image\n",
        "            if horizontal:\n",
        "                image = iteration(image, hvalue)   \n",
        "\n",
        "            # RUN LENGTH SMOOTHING ALGORITHM working vertically on the image\n",
        "            if vertical:\n",
        "                image = image.T\n",
        "                image = iteration(image, vvalue)\n",
        "                image = image.T\n",
        "\n",
        "        except (AttributeError, ValueError) as e:\n",
        "            image = None\n",
        "            print(\"ERROR: \", e, \"\\n\")\n",
        "            print('Image must be an numpy ndarray and must be in \"binary\". Use Opencv/PIL to convert the image to binary.\\n')\n",
        "            print(\"import cv2;\\nimage=cv2.imread('path_of_the_image');\\ngray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY);\\n\\\n",
        "                (thresh, image_binary) = cv2.threshold(gray, 150, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)\\n\")\n",
        "            print(\"method usage -- rlsa.rlsa(image_binary, True, False, 10)\")\n",
        "    else:\n",
        "        print('Image must be an numpy ndarray and must be in binary')\n",
        "        image = None\n",
        "    return image\n",
        "\n",
        "def hpp(image: np.ndarray):\n",
        "  hp = [0]*image.shape[0]\n",
        "  for i in range(0,image.shape[0]):\n",
        "    hp[i]=0\n",
        "    for j in range(0,image.shape[1]):\n",
        "      hp[i] += image[i][j]\n",
        "  return hp\n",
        " \n",
        "def split_lines(img: np.ndarray,count):\n",
        "  hp = hpp(~img)\n",
        "  #cv2_imshow(img)\n",
        "  #print(\"HPP\",hp)\n",
        "  peaks, _ = find_peaks(hp, height=0)\n",
        "  #peaks, _ = find_peaks(hp, distance=91)      #make distance relative\n",
        "  xhp=np.array(hp)/1000\n",
        "  peaks, _ = find_peaks(xhp, prominence=38)\n",
        "  print(\"peaks:\",peaks)\n",
        "  plt.plot(xhp)\n",
        "  plt.plot(peaks, xhp[peaks], \"x\")\n",
        "  a=0\n",
        "  for i in range(0,len(peaks)-1):\n",
        "    min_ind=hp.index(min(hp[peaks[i]:peaks[i+1]]),peaks[i],peaks[i+1])\n",
        "    #print(\"Min index \", min_ind,\" between \", peaks[i], \"and \",peaks[i+1], \"value:\",hp[min_ind])\n",
        "    split1 = img[a:min_ind]\n",
        "    a = min_ind\n",
        "    print(\"Split Line \",i+1)\n",
        "    count += 1\n",
        "    save(\"lines/line\"+str(count)+\".jpg\",split1)\n",
        "    # cv2_imshow(split1)\n",
        "    wordseg(split1)\n",
        "  split1=img[min_ind:]\n",
        "  print(\"Split Line \",i+2)\n",
        "  count += 1\n",
        "  save(\"lines/line\"+str(count)+\".jpg\",split1)\n",
        "  # cv2_imshow(split1)\n",
        "  wordseg(split1)\n",
        "  return len(peaks)\n",
        "\n",
        "def mask(gray,roi_thresh,ctr,x,y,w,h):\n",
        "  mask=~np.zeros_like(gray)\n",
        "  cv2.drawContours(mask,[ctr],0, (0,0,0), -1)\n",
        "  roi_mask=mask[y:y+h,x:x+w]\n",
        "  roi_thresh=cv2.bitwise_or(roi_mask,roi_thresh)\n",
        "  return roi_thresh\n",
        "\n",
        "def save(path, img):\n",
        "    #tmp = np.asarray(img*255.0, dtype=np.uint8)\n",
        "    Image.fromarray(img).save(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26OFEPMNhhAs"
      },
      "source": [
        "def charseg(word):\n",
        "  global wcount, lcount, chcount\n",
        "  # Morphological Closing\n",
        "  kernel = np.ones((3,3), np.uint8)\n",
        "  closed=cv2.morphologyEx(~word,cv2.MORPH_CLOSE,kernel)\n",
        "  # print(\"Word after RLSA\")\n",
        "  cv2_imshow(closed)\n",
        "\n",
        "  #Finding  and sorting Contours\n",
        "  ctrs, hier = cv2.findContours(closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  sorted_ctrs = sorted(ctrs, key=lambda ctr: (cv2.boundingRect(ctr)[0]))\n",
        "  count = 0  # to store number of words\n",
        "    #Extracting characters from the word\n",
        "\n",
        "  for i, ctr in enumerate(sorted_ctrs):\n",
        "    #Getting bounding box of character\n",
        "    x, y, w, h = cv2.boundingRect(ctr)\n",
        "    #Getting ROI of character from ROI of word \n",
        "    roi = word[y:y+h, x:x+w]\n",
        "\n",
        "    #Only characters greater than a particular size are extracted\n",
        "    #This cutoff should be smaller then smallest character to avoid loss of character\n",
        "    if(roi.shape[0]>12 and roi.shape[1]>11):\n",
        "      print('\\n\\n\\ncharacter segment no:'+str(i))\n",
        "      print(\"Height: \",roi.shape[0], \"Width: \",roi.shape[1])\n",
        "      #print(\"Location:\\tx: \",cx,\"\\ty: \",cy)\n",
        "      charoi = mask(word,roi,ctr,x,y,w,h)\n",
        "      cv2_imshow(charoi)\n",
        "      chcount += 1\n",
        "      count += 1\n",
        "      save(\"chars/char\"+str(chcount)+\"(\"+str(lcount)+\")\"+\".jpg\",roi)\n",
        "      # save(\"drive/MyDrive/testchars/\"+str(chcount)+\".jpg\",roi)\n",
        "  print(\"No. of characters: \",count)\n",
        "  print(\"Cumulative character count: \",chcount)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2z5kAn_iLz6d"
      },
      "source": [
        "def wordseg(line):\n",
        "  global wcount, lcount\n",
        "  # Morphological Closing\n",
        "  kernel = np.ones((22,image.shape[1]//55), np.uint8)\n",
        "  closed=cv2.morphologyEx(~line,cv2.MORPH_CLOSE,kernel)\n",
        "  # print(\"Closed line\")\n",
        "  # cv2_imshow(closed)\n",
        "\n",
        "  #Finding  and sorting Contours\n",
        "  ctrs, hier = cv2.findContours(closed, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  sorted_ctrs = sorted(ctrs, key=lambda ctr: (cv2.boundingRect(ctr)[0]))\n",
        "  # copy_img = line.copy()\n",
        "  # print(\"Word Contours\")\n",
        "  # cv2.drawContours(copy_img, ctrs, -1, (0, 255, 0), 3)\n",
        "  # cv2_imshow(copy_img) \n",
        "\n",
        "  count = 0  # to store number of words\n",
        "  for i, ctr in enumerate(sorted_ctrs):\n",
        "      # Get bounding box\n",
        "      x, y, w, h = cv2.boundingRect(ctr)\n",
        "      # Getting ROI from original image\n",
        "      roi = line[y:y+h, x:x+w]\n",
        "      #print('\\n\\n\\nsegment no:'+str(i))\n",
        "      #print(\"Height: \",roi.shape[0], \"Width: \",roi.shape[1])\n",
        "\n",
        "      # Only words of greater than a particular size are selected\n",
        "      if(roi.shape[1]>image.shape[1]//50):\n",
        "          print('Word segment no:',count)\n",
        "          print(\"Location:\\tx: \",x,\"\\ty: \",y)\n",
        "          cv2_imshow(roi)\n",
        "          count = count+1\n",
        "          wcount = wcount+1\n",
        "          char_count=0\n",
        "          save(\"words/word\"+str(wcount)+\"(\"+str(lcount)+\")\"+\".jpg\",roi)\n",
        "          charseg(roi)\n",
        "      \n",
        "\n",
        "  print(\"Total number of words: \",count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lqb-zqhriEhh"
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from scipy.signal import find_peaks\n",
        "from matplotlib import pyplot as plt\n",
        "from statistics import mean, stdev\n",
        "from google.colab.patches import cv2_imshow\n",
        "from google.colab import files\n",
        "\n",
        "#Loading image\n",
        "image = cv2.imread(\"/content/drive/MyDrive/malayalam1/p_mal_0103.tif\");\n",
        "cv2_imshow(image)                             # display original image\n",
        "\n",
        "#Creating directory to store segmented lines\n",
        "os.makedirs(\"lines\", exist_ok=True)\n",
        "os.makedirs(\"words\", exist_ok=True)\n",
        "os.makedirs(\"chars\", exist_ok=True)\n",
        "\n",
        "#Converting to Grayscale\n",
        "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
        "print(\"Height: \",image.shape[0], \"Width: \",image.shape[1])\n",
        "#print(\"Grayscale Image\")\n",
        "#cv2_imshow(gray)\n",
        "\n",
        "#Thresholding\n",
        "ret,thresh = cv2.threshold(gray,160,255,cv2.THRESH_BINARY) \n",
        "#print(\"After thresholding\")\n",
        "#cv2_imshow(thresh)\n",
        "\n",
        "\n",
        "         #@title Kernel size parameters for Morphological Closing\n",
        "print(\"Closing\")\n",
        "ver = 660 #@param {type:'slider', min:1,max: 1270}\n",
        "hor = 10 #@param {type:'slider', min:1,max:70}\n",
        "lh = 23 #@param {type:'slider', min:1,max:100}\n",
        "kernel = np.ones((image.shape[0]//ver,image.shape[1]//hor), np.uint8)\n",
        "closing=cv2.morphologyEx(~thresh,cv2.MORPH_CLOSE,kernel)\n",
        "#closing=hvrlsa(thresh.copy(),True,True,image.shape[1]//hor,lh)\n",
        "cv2_imshow(closing)\n",
        "lcount = 0\n",
        "wcount = 0\n",
        "chcount = 0\n",
        "\n",
        "ctrs, hier = cv2.findContours(closing.copy(), cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)\n",
        "copy_img = image.copy()\n",
        "cv2.drawContours(copy_img, ctrs, -1, (0, 255, 0), 3)\n",
        "cv2_imshow(copy_img)\n",
        "\n",
        "\n",
        "                  #sort contours\n",
        "sorted_ctrs = sorted(ctrs, key=lambda ctr: cv2.boundingRect(ctr)[1])\n",
        "print(\"Number of line contours:\", len(sorted_ctrs))\n",
        "ctr_height = []   #to store height of each contour\n",
        "for i, ctr in enumerate(sorted_ctrs):\n",
        "  _,_,w,h = cv2.boundingRect(ctr)\n",
        "  if(w>image.shape[1]//50 and h>image.shape[0]//40):\n",
        "    ctr_height.append(h)\n",
        "avg_height = mean(ctr_height)\n",
        "print(\"avg height: \",avg_height)\n",
        "print(\"undersegmentation threshold: \",avg_height*1.45)\n",
        "print(len(ctr_height),\" ctr heights: \",ctr_height)\n",
        "ucount =0\n",
        "for i, ctr in enumerate(sorted_ctrs):\n",
        " \n",
        "    # Get bounding box\n",
        "    x, y, w, h = cv2.boundingRect(ctr)\n",
        " \n",
        "    # Getting ROI\n",
        "    roi = image[y:y+h, x:x+w]\n",
        "    roi_thresh=thresh[y:y+h,x:x+w]\n",
        "    if(roi.shape[1]>image.shape[1]//50 and roi.shape[0]>image.shape[0]//40):\n",
        "      if(roi.shape[0]<avg_height*1.45):         #undersegmentation threshold\n",
        "        roi_thresh = mask(gray,roi_thresh,ctr,x,y,w,h)\n",
        "        \n",
        "        # show ROI\n",
        "        print('\\n\\n\\nsegment no:'+str(i))\n",
        "        print(\"Height: \",roi.shape[0], \"Width: \",roi.shape[1])\n",
        "        print(\"Location:\\tx: \",x,\"\\ty: \",y)\n",
        "        #cv2_imshow(roi)\n",
        "        # cv2_imshow(roi_thresh)\n",
        "        lcount=lcount+1 \n",
        "        save(\"lines/line\"+str(lcount)+\".jpg\",roi_thresh)\n",
        "   \n",
        "        print('Line segment no:',lcount)\n",
        "        #plt.imshow(roi)\n",
        "        #plt.show()\n",
        "        #cv2_imshow(roi)\n",
        "        #cv2.imwrite(\"/home/word_seg_project/word_output/\"+\"00\"+str(count)+\".jpg\",roi)\n",
        "        wordseg(roi_thresh)\n",
        "        \n",
        "      else:\n",
        "        print(\"Undersegmented line\")\n",
        "        print(\"Height: \",roi.shape[0], \"Width: \",roi.shape[1])\n",
        "        cv2_imshow(roi)\n",
        "        ucount+=1\n",
        "        lcount+=split_lines(roi_thresh, lcount)\n",
        "        #hp=hpp(roi)\n",
        "        #for i in range(0,len(hp)):\n",
        "          #print(\"Horizontal Pp row \", i,hp[i])\n",
        "        #cv2.rectangle(image,(x,y),( x + w, y + h ),(90,0,255),2)\n",
        "\n",
        "\n",
        "print(f\"Final line count {lcount} undersegmented count: {ucount}\")\n",
        "print(f\"Word count: {wcount}\\tCharacter count: {chcount}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kTgWbygNMvOv"
      },
      "source": [
        "TO do:\n",
        "\n",
        "  - Analyse undersegmented images (15)\n",
        "  - Analyse incorrrectly segmented images (10)\n",
        "  - Find and analyse images which miss chandrakala to identify ideal parameter value for kernel"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kqrRO758ukCv"
      },
      "source": [
        "# import os\n",
        "# dir = '/content/drive/MyDrive/testchars/'\n",
        "# for f in os.listdir(dir):\n",
        "    # os.remove(os.path.join(dir, f))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}